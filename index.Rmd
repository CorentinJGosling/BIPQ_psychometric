---
title: "Supplementary for : "
author: "Miss Blandine, Prof Yannick, and the rest (the plebe people)"
date: "2025-09-17"
output: 
  html_document:
    toc: true
    toc_float: true
    
---


```{r, echo=FALSE}
# control + alt + i = crée un bloc de code
# les #, ##, ### hors des blocs de code = niveaux de titre (1, 2, 3)
# kniter pour rendre le format HTML
# créer un ficher .gitignore (tu vas dans le terminal click droit sur le dossier git et tu tapes : touch .gitignore) et rentrer le nom de votre fichier de données pour ne pas le rendre accessible gratuitement sur github (quoi que si tu fais l'erreur, j'en profiterai!! :) )
```


```{r, echo=FALSE, message=FALSE, results='hide', warning=FALSE}
# j'ai enlevé les install packages, énormément de place pour peu de bénéfice, on sait tous installer un package ici, nous sommes des gens civilisés :) 
# {r, echo=FALSE, message=FALSE, results='hide', warning=FALSE} => veut dire de cacher le text (echo=FALSE) et l'output (des warning au chargement de chaque package)
# globalement c'est une très mauvaise pratique de charger toutes les library car ça peut créer des conflicts. Pour les packages dont on utilise une seule fonction une fois, préférer nom_dupackage::nom_de_la_fonction()

library(summarytools)
library(psych)
library(psychTools)
library(psy)
library(lavaan)
library(parameters)
library(datawizard)
library(dplyr)
library(kableExtra)
#library(semTable) sem Table was removed from CRAN
library(semTools)
library(semPlot)
library(tidySEM)
library(lavaanPlot)
library(BifactorIndicesCalculator)
library(tidyLPA)

library(readxl)
library(psych)
library(corrplot)
```

```{r, echo=FALSE, message=FALSE, results='hide', warning=FALSE}
df <- read_excel("C:/Users/Blandine _Thibout/Searches/Etude_psycho_BIPQ/CompareDep_redress_rakenorm_160525.xlsx")

gad <- read_excel("C:/Users/Blandine _Thibout/Searches/Etude_psycho_BIPQ/pop_GAD7_20240403.xlsx")
variables <-c("id_unik", "score_GAD7", "nerveux",	"inquiet",	"inquiet_exces",	"difficult_detente",	"agitation",	"tendance_contrarie",	"sentiment_peur"
)
gad<-gad[, c(variables)]

# Forcer la conversion en numérique et traiter les erreurs de conversion
# !!! NE JAMAIS FAIRE as.numeric sans as.character !!!
# bon = df$poids_norm <- as.numeric(as.character(df$poids_norm))
df$poids_norm <- as.numeric(df$poids_norm)

# Vérifier le type après conversion
str(df$poids_norm)

# Garder uniquement les variables d’intérêt + poids
items <- c("stigma_percept_1", "stigma_percept_2", "stigma_percept_3", "stigma_percept_4",
           "stigma_percept_5", "stigma_percept_6", "stigma_percept_7", "stigma_percept_8")

data_efa <- df[, c(items)]

```

# S1. Sample description
```{r}
# ici on fait une table 1 de l'échantillon
# https://www.rdocumentation.org/packages/table1/versions/1.5.1
```

# S2. Variable description
```{r}
# ici je veux voir des densités et histogrammes, et cherry on the cake des résidus de modèles 
```

# S3. Internal consistency{.tabset}

## Distribution des items
```{r}
# j'imagine que les yeux saignent, organiser dans une table ? 
describe(data_efa$stigma_percept_1)$skew
describe(data_efa$stigma_percept_1)$kurtosis

describe(data_efa$stigma_percept_2)$skew
describe(data_efa$stigma_percept_2)$kurtosis

describe(data_efa$stigma_percept_3)$skew
describe(data_efa$stigma_percept_3)$kurtosis

describe(data_efa$stigma_percept_4)$skew
describe(data_efa$stigma_percept_4)$kurtosis

describe(data_efa$stigma_percept_5)$skew
describe(data_efa$stigma_percept_5)$kurtosis

describe(data_efa$stigma_percept_6)$skew
describe(data_efa$stigma_percept_6)$kurtosis

describe(data_efa$stigma_percept_7)$skew
describe(data_efa$stigma_percept_7)$kurtosis

describe(data_efa$stigma_percept_8)$skew
describe(data_efa$stigma_percept_8)$kurtosis

```

## ICC
```{r}
# Supposons que ton dataframe s'appelle data_efa
# et que tes items sont stigma_percept_1 à stigma_percept_5
items <- data_efa[, c("stigma_percept_1",
                      "stigma_percept_2",
                      "stigma_percept_3",
                      "stigma_percept_4",
                      "stigma_percept_5",
                      "stigma_percept_6",
                      "stigma_percept_7",
                      "stigma_percept_8")]

# Calculer la matrice de corrélation de Spearman
iic <- cor(items, method = "spearman", use = "pairwise.complete.obs")

# Afficher la matrice
print(round(iic, 2))

# Heatmap simple
corrplot(iic, method = "color", type = "upper",
         addCoef.col = "black", # ajoute les valeurs
         tl.col = "black", tl.srt = 45,
         diag = FALSE)

```

## ITC
```{r}
# Calculer Cronbach's alpha et les item-total correlations
alpha_result <- alpha(items, check.keys = TRUE)

# Afficher les résultats
alpha_result

# Les corrected item-total correlations sont dans :
alpha_result$item.stats$r.drop
```

## Cronbach 

```{r}
# Alpha avec correction automatique des items inversés
alpha <- alpha(items, check.keys = TRUE)

# Afficher les résultats complets
alpha

```

## Omega

```{r}
# Omega total (unidimensionnel)
omega_result <- omega(items, nfactors = 1, fm = "ml")  # fm = "ml" pour maximum likelihood

# Afficher les résultats
omega_result

```

## Floor ceiling

```{r}
### floor et ceiling effect 

# Calculer floor et ceiling effect pour chaque item
floor_ceiling <- sapply(items, function(x) {
  floor_effect <- sum(x == min(x, na.rm = TRUE)) / length(na.omit(x)) * 100
  ceiling_effect <- sum(x == max(x, na.rm = TRUE)) / length(na.omit(x)) * 100
  c(Floor = round(floor_effect, 1), Ceiling = round(ceiling_effect, 1))
})

# Afficher le tableau
floor_ceiling <- t(floor_ceiling)
floor_ceiling

# Résumé complet et visuel de tous les items
dfSummary(items,
          headings = FALSE,   # pour afficher moins de texte
          graph.magnif = 0.8, # taille des graphiques
          valid.col = FALSE,  # cacher colonne des valeurs valides
          style = "grid")     # style visuel agréable
# Ajouter floor/ceiling dans dfSummary
summary_items <- dfSummary(items)
print(summary_items, method = "render")  # pour affichage HTML dans RStudio <- merci !!!! il existe le package kableExtra qui est fait pour ça autrement
```

# S4. 
```{r}

```


```{r, eval=FALSE,include=FALSE}
#######################################################################################
#######################################################################################
#################  Structural validity   ##############################################
#######################################################################################
#######################################################################################

#####  CFA 

### unidimensionnel

cfa_model <- '
Stigma =~ stigma_percept_1 + stigma_percept_2 + stigma_percept_3 + stigma_percept_4 +
          stigma_percept_5 + stigma_percept_6 + stigma_percept_7 + stigma_percept_8
'
fit <- cfa(cfa_model, data = data_efa, estimator = "MLR") # MLR = robust to non-normality
summary(fit, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)

fit_indices <- fitMeasures(fit, c("cfi", "tli", "rmsea", "srmr"))


semPaths(fit, "std", whatLabels = "std", layout = "circle")


### model 1 

cfa_model_multi <- '
F1 =~ stigma_percept_1 + stigma_percept_5 + stigma_percept_6 + stigma_percept_8
F2 =~ stigma_percept_3 + stigma_percept_4 + stigma_percept_7
# Item 2 n’appartient à aucun facteur, il reste indépendant
'
fit_multi <- cfa(cfa_model_multi, data = data_efa, estimator = "MLR")
summary(fit_multi, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)


### model 2 

cfa_model_multi_2 <- '
F1 =~ stigma_percept_1 + stigma_percept_1 + stigma_percept_5 + stigma_percept_6 + stigma_percept_8
F2 =~ stigma_percept_3 + stigma_percept_4 + stigma_percept_7
'
fit_multi_2 <- cfa(cfa_model_multi_2, data = data_efa, estimator = "MLR")
summary(fit_multi_2, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)


#######################################################################################
#######################################################################################
#################  hypothesis testing    ##############################################
#######################################################################################
#######################################################################################

dff <- merge(df, gad, by = "id_unik", all.x = TRUE)

df_bis <- dff %>%
  select(score_PHQ9, Score_autostigma, Score_BIPQ, Score_whodas, score_GAD7)
summary(df_bis)

# convergent validity 
# 1- with simple correlation
cor_spearman <- cor(df_bis$Score_BIPQ, df_bis$Score_autostigma, method = "spearman", use = "complete.obs")

cor_spearman
cor.test(df_bis$Score_BIPQ, df_bis$Score_autostigma, method = "spearman")


cor_spearman2 <- cor(df_bis$Score_BIPQ, df_bis$score_PHQ9, method = "spearman", use = "complete.obs")

cor_spearman2
cor.test(df_bis$Score_BIPQ, df_bis$score_PHQ9, method = "spearman")

cor_spearman3 <- cor(df_bis$Score_BIPQ, df_bis$score_GAD7, method = "spearman", use = "complete.obs")

cor_spearman3
cor.test(df_bis$Score_BIPQ, df_bis$score_GAD7, method = "spearman")

# 2- with latent model 

### model 1 
var_sss <- c("id_unik", "Score_autostigma", "stigma_auto_1",	"stigma_auto_2",	"stigma_auto_3",	"stigma_auto_4",	"stigma_auto_5",	"stigma_auto_6",	"stigma_auto_7", "stigma_auto_8", "stigma_auto_9",
             "Score_BIPQ", "stigma_percept_1", "stigma_percept_2", "stigma_percept_3", "stigma_percept_4","stigma_percept_5", "stigma_percept_6", "stigma_percept_7", "stigma_percept_8"
)
data_sss <-dff[, c(var_sss)]
summary(data_sss)

cfa_model_SSS <- '
BIPQ =~ stigma_percept_1 + stigma_percept_5 + stigma_percept_6 + stigma_percept_8 + stigma_percept_3 + stigma_percept_4 + stigma_percept_7 + stigma_percept_2
SSS =~ stigma_auto_1 + stigma_auto_2 + stigma_auto_3 + stigma_auto_4 + stigma_auto_5 + stigma_auto_6 + stigma_auto_7 + stigma_auto_8 + stigma_auto_9
'
fit_SSS <- cfa(cfa_model_SSS, data = data_sss, estimator = "MLR")
summary(fit_SSS, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)

fit_SSS_Missing <- cfa(
  cfa_model_SSS,
  data = data_sss,
  estimator = "MLR",
  missing = "fiml"
)
summary(fit_SSS_Missing, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)

# with free correlation

cfa_SSS_corr_libre <- '
BIPQ =~ stigma_percept_1 + stigma_percept_5 + stigma_percept_6 + 
        stigma_percept_8 + stigma_percept_3 + stigma_percept_4 + 
        stigma_percept_7 + stigma_percept_2

SSS =~ stigma_auto_1 + stigma_auto_2 + stigma_auto_3 + stigma_auto_4 + stigma_auto_5 + stigma_auto_6 + stigma_auto_7 + stigma_auto_8 + stigma_auto_9

# corrélation libre entre facteurs
BIPQ ~~ SSS
'

fit_SSS_corr_libre <- cfa(
  cfa_SSS_corr_libre,
  data = data_sss,
  estimator = "MLR",
  missing = "fiml"  # essaye avec et sans cette ligne
)

summary(fit_SSS_corr_libre , fit.measures = TRUE, standardized = TRUE)


# avec contrainte d'égalité à 0

cfa_SSS_corr_0 <- '
BIPQ =~ stigma_percept_1 + stigma_percept_5 + stigma_percept_6 + 
        stigma_percept_8 + stigma_percept_3 + stigma_percept_4 + 
        stigma_percept_7 + stigma_percept_2

SSS =~ stigma_auto_1 + stigma_auto_2 + stigma_auto_3 + stigma_auto_4 + stigma_auto_5 + stigma_auto_6 + stigma_auto_7 + stigma_auto_8 + stigma_auto_9

# corrélation contrainte à 0
BIPQ ~~ 0*SSS
'

fit_SSS_corr_0 <- cfa(
  cfa_SSS_corr_0,
  data = data_sss,
  estimator = "MLR",
  missing = "fiml"  # essaye avec et sans cette ligne
)

summary(fit_SSS_corr_0, fit.measures = TRUE, standardized = TRUE)

# Si le test est significatif :la contrainte (corrélation = 0) dégrade le modèle donc les facteurs sont significativement corrélés
# lance une fois avec les deux cfa avec Missing et sans 

lavTestLRT(fit_SSS_corr_libre, fit_SSS_corr_0)

# maintenant model cfa 1 facteur

cfa_model_SSS_1 <- '
BIPQSSS =~ stigma_percept_1 + stigma_percept_5 + stigma_percept_6 + stigma_percept_8 + stigma_percept_3 + stigma_percept_4 + stigma_percept_7 + stigma_percept_2
 + stigma_auto_1 + stigma_auto_2 + stigma_auto_3 + stigma_auto_4 + stigma_auto_5 + stigma_auto_6 + stigma_auto_7 + stigma_auto_8 + stigma_auto_9
'
fit_SSS_1 <- cfa(cfa_model_SSS_1, data = data_sss, estimator = "MLR")
summary(fit_SSS_1, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)

fit_SSS_Missing_1 <- cfa(
  cfa_model_SSS_1,
  data = data_sss,
  estimator = "MLR",
  missing = "fiml" 
)
summary(fit_SSS_Missing_1, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)

### model 2 

var_phq <- c("id_unik", "score_PHQ9", "interet_plaisir",	"triste_deprime",	"sommeil",	"fatigue",	"appetit",	"opinion_soi",	"concentration",	"activite",	"consequence_pb",
             
             "Score_BIPQ", "stigma_percept_1", "stigma_percept_2", "stigma_percept_3", "stigma_percept_4","stigma_percept_5", "stigma_percept_6", "stigma_percept_7", "stigma_percept_8"
)
data_phq <-dff[, c(var_phq)]
summary(data_phq)


cfa_model_PHQ <- '
BIPQ =~ stigma_percept_1 + stigma_percept_5 + stigma_percept_6 + stigma_percept_8 + stigma_percept_3 + stigma_percept_4 + stigma_percept_7 + stigma_percept_2
PHQ9 =~ interet_plaisir + triste_deprime + sommeil + fatigue + appetit + opinion_soi + concentration + activite + consequence_pb
'
fit_PHQ <- cfa(cfa_model_PHQ, data = data_phq, estimator = "MLR")
summary(fit_PHQ, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)

fit_PHQ_Missing <- cfa(
  cfa_model_PHQ,
  data = data_phq,
  estimator = "MLR",
  missing = "fiml"
)
summary(fit_PHQ_Missing, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)

# with free correlation

cfa_PHQ_corr_libre <- '
BIPQ =~ stigma_percept_1 + stigma_percept_5 + stigma_percept_6 + 
        stigma_percept_8 + stigma_percept_3 + stigma_percept_4 + 
        stigma_percept_7 + stigma_percept_2

PHQ9 =~ interet_plaisir + triste_deprime + sommeil + fatigue + appetit + opinion_soi + concentration + activite + consequence_pb

# corrélation libre entre facteurs
BIPQ ~~ PHQ9
'

fit_PHQ_corr_libre <- cfa(
  cfa_PHQ_corr_libre,
  data = data_phq,
  estimator = "MLR",
  missing = "fiml"  # essaye avec et sans cette ligne
)

summary(fit_PHQ_corr_libre , fit.measures = TRUE, standardized = TRUE)


# avec contrainte d'égalité à 0

cfa_PHQ_corr_0 <- '
BIPQ =~ stigma_percept_1 + stigma_percept_5 + stigma_percept_6 + 
        stigma_percept_8 + stigma_percept_3 + stigma_percept_4 + 
        stigma_percept_7 + stigma_percept_2

PHQ9 =~ interet_plaisir + triste_deprime + sommeil + fatigue + appetit + opinion_soi + concentration + activite + consequence_pb

# corrélation contrainte à 0
BIPQ ~~ 0*PHQ9
'

fit_PHQ_corr_0 <- cfa(
  cfa_PHQ_corr_0,
  data = data_phq,
  estimator = "MLR",
  missing = "fiml"  # essaye avec et sans cette ligne
)

summary(fit_PHQ_corr_0, fit.measures = TRUE, standardized = TRUE)

# Si le test est significatif :la contrainte (corrélation = 0) dégrade le modèle donc les facteurs sont significativement corrélés
# lance une fois avec les deux cfa avec Missing et sans 

lavTestLRT(fit_PHQ_corr_libre, fit_PHQ_corr_0)

# maintenant model cfa 1 facteur

cfa_model_PHQ_1 <- '
BIPQPHQ9 =~ stigma_percept_1 + stigma_percept_5 + stigma_percept_6 + stigma_percept_8 + stigma_percept_3 + stigma_percept_4 + stigma_percept_7 + stigma_percept_2
 + interet_plaisir + triste_deprime + sommeil + fatigue + appetit + opinion_soi + concentration + activite + consequence_pb
'
fit_PHQ_1 <- cfa(cfa_model_PHQ_1, data = data_phq, estimator = "MLR")
summary(fit_PHQ_1, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)

fit_PHQ_Missing_1 <- cfa(
  cfa_model_PHQ_1,
  data = data_phq,
  estimator = "MLR",
  missing = "fiml" 
)
summary(fit_PHQ_Missing_1, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)

### model 3 

var_gad <- c("id_unik", "score_GAD7", "nerveux",	"inquiet",	"inquiet_exces",	"difficult_detente",	"agitation",	"tendance_contrarie",	"sentiment_peur",
             "Score_BIPQ", "stigma_percept_1", "stigma_percept_2", "stigma_percept_3", "stigma_percept_4","stigma_percept_5", "stigma_percept_6", "stigma_percept_7", "stigma_percept_8"
)
data_gad<-dff[, c(var_gad)]
summary(data_gad)

cfa_model_GAD <- '
BIPQ =~ stigma_percept_1 + stigma_percept_5 + stigma_percept_6 + stigma_percept_8 + stigma_percept_3 + stigma_percept_4 + stigma_percept_7 + stigma_percept_2
GAD =~ nerveux + inquiet + inquiet_exces + difficult_detente + agitation + tendance_contrarie + sentiment_peur
'
fit_GAD <- cfa(cfa_model_GAD, data = data_gad, estimator = "MLR")
summary(fit_GAD, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)

fit_GAD_Missing <- cfa(
  cfa_model_GAD,
  data = data_gad,
  estimator = "MLR",
  missing = "fiml"
)
summary(fit_GAD_Missing, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)

# with free correlation

cfa_GAD_corr_libre <- '
BIPQ =~ stigma_percept_1 + stigma_percept_5 + stigma_percept_6 + 
        stigma_percept_8 + stigma_percept_3 + stigma_percept_4 + 
        stigma_percept_7 + stigma_percept_2

GAD =~ nerveux + inquiet + inquiet_exces + difficult_detente + 
       agitation + tendance_contrarie + sentiment_peur

# corrélation libre entre facteurs
BIPQ ~~ GAD
'

fit_GAD_corr_libre <- cfa(
  cfa_GAD_corr_libre,
  data = data_gad,
  estimator = "MLR",
  missing = "fiml"  # essaye avec et sans cette ligne
)

summary(fit_GAD_corr_libre , fit.measures = TRUE, standardized = TRUE)


# avec contrainte d'égalité à 0

cfa_GAD_corr_0 <- '
BIPQ =~ stigma_percept_1 + stigma_percept_5 + stigma_percept_6 + 
        stigma_percept_8 + stigma_percept_3 + stigma_percept_4 + 
        stigma_percept_7 + stigma_percept_2

GAD =~ nerveux + inquiet + inquiet_exces + difficult_detente + 
       agitation + tendance_contrarie + sentiment_peur

# corrélation contrainte à 0
BIPQ ~~ 0*GAD
'

fit_GAD_corr_0 <- cfa(
  cfa_GAD_corr_0,
  data = data_gad,
  estimator = "MLR",
  missing = "fiml"  # essaye avec et sans cette ligne
)

summary(fit_GAD_corr_0, fit.measures = TRUE, standardized = TRUE)

# Si le test est significatif :la contrainte (corrélation = 0) dégrade le modèle donc les facteurs sont significativement corrélés
# lance une fois avec les deux cfa avec Missing et sans 

lavTestLRT(fit_GAD_corr_libre, fit_GAD_corr_0)

# maintenant model cfa 1 facteur

cfa_model_GAD_1 <- '
BIPQGAD =~ stigma_percept_1 + stigma_percept_5 + stigma_percept_6 + stigma_percept_8 + stigma_percept_3 + stigma_percept_4 + stigma_percept_7 + stigma_percept_2
 + nerveux + inquiet + inquiet_exces + difficult_detente + agitation + tendance_contrarie + sentiment_peur
'
fit_GAD_1 <- cfa(cfa_model_GAD_1, data = data_gad, estimator = "MLR")
summary(fit_GAD_1, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)

fit_GAD_Missing_1 <- cfa(
  cfa_model_GAD_1,
  data = data_gad,
  estimator = "MLR",
  missing = "fiml"
)
summary(fit_GAD_Missing_1, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE)


#######################################################################################
#######################################################################################
#################  incremental validity    ############################################
#######################################################################################
#######################################################################################


# Modèle A : WHODAS ~ PHQ9 + SSS + GAD
modelA <- lm(Score_whodas ~ score_PHQ9 + Score_autostigma + score_GAD7, data = df_bis)

# Modèle B : WHODAS ~ PHQ9 + SSS + GAD + BIPQ
modelB <- lm(Score_whodas ~ score_PHQ9 + Score_autostigma + score_GAD7 + Score_BIPQ, data = df_bis)

anova_result <- anova(modelA, modelB)
anova_result


############ code corentin

library(psych)
library(MASS)
install.packages('yhat')
library(yhat)
library(boot)


## Commonality analysis 
df_clean <- df_bis[complete.cases(df_bis[, c("Score_whodas",
                                             "score_PHQ9",
                                             "Score_autostigma",
                                             "score_GAD7",
                                             "Score_BIPQ")]), ]
# 1574 observations

res_lm <- lm(Score_whodas ~ score_PHQ9 + Score_autostigma + score_GAD7 + Score_BIPQ,
             data = df_clean)
res_dom <- calc.yhat(res_lm)
boot.out = boot(data=df_clean, yhat::boot.yhat, 1000, 
                lmOut=res_lm, regrout0=res_dom)
boot_results = booteval.yhat(res_dom, boot.out,bty="perc",.95,3)

results_filtered <- boot_results$combCIaps["score_PHQ9,Score_autostigma,score_GAD7", "Score_BIPQ.Inc"] # d'abord la part de variance du whodas expliquée par les 3 qst, puis la validité incrémentale de la BIPQ

print(results_filtered)




```

